nohup: ignoring input
Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
================================================================================
心理健康对话模型评估系统
================================================================================
加载测试数据...
测试集大小: 1609
使用 30 个测试样本
将评估 6 个模型:
  - Base Qwen1.5-4B
  - Finetuned Qwen1.5-4B
  - Base chatglm3-6b
  - Finetuned chatglm3-6b
  - Base Qwen2.5-7B
  - Finetuned Qwen2.5-7B

评估模型: Base Qwen1.5-4B
============================================================
加载模型: Qwen/Qwen1.5-4B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.90s/it]
  生成 Base Qwen1.5-4B 的回复...
生成 Base Qwen1.5-4B 的回复:   0%|          | 0/30 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
生成 Base Qwen1.5-4B 的回复:   3%|▎         | 1/30 [00:20<09:49, 20.32s/it]生成 Base Qwen1.5-4B 的回复:   7%|▋         | 2/30 [01:16<19:21, 41.48s/it]生成 Base Qwen1.5-4B 的回复:  10%|█         | 3/30 [01:43<15:35, 34.67s/it]生成 Base Qwen1.5-4B 的回复:  13%|█▎        | 4/30 [02:04<12:40, 29.25s/it]生成 Base Qwen1.5-4B 的回复:  17%|█▋        | 5/30 [02:27<11:13, 26.95s/it]生成 Base Qwen1.5-4B 的回复:  20%|██        | 6/30 [02:46<09:48, 24.52s/it]生成 Base Qwen1.5-4B 的回复:  23%|██▎       | 7/30 [03:04<08:31, 22.22s/it]生成 Base Qwen1.5-4B 的回复:  27%|██▋       | 8/30 [04:01<12:16, 33.48s/it]生成 Base Qwen1.5-4B 的回复:  30%|███       | 9/30 [04:59<14:21, 41.02s/it]生成 Base Qwen1.5-4B 的回复:  33%|███▎      | 10/30 [05:56<15:17, 45.85s/it]生成 Base Qwen1.5-4B 的回复:  37%|███▋      | 11/30 [06:48<15:07, 47.74s/it]生成 Base Qwen1.5-4B 的回复:  40%|████      | 12/30 [07:45<15:09, 50.56s/it]生成 Base Qwen1.5-4B 的回复:  43%|████▎     | 13/30 [08:03<11:34, 40.83s/it]生成 Base Qwen1.5-4B 的回复:  47%|████▋     | 14/30 [09:00<12:12, 45.77s/it]生成 Base Qwen1.5-4B 的回复:  50%|█████     | 15/30 [09:51<11:47, 47.19s/it]生成 Base Qwen1.5-4B 的回复:  53%|█████▎    | 16/30 [10:48<11:44, 50.35s/it]生成 Base Qwen1.5-4B 的回复:  57%|█████▋    | 17/30 [11:27<10:08, 46.77s/it]生成 Base Qwen1.5-4B 的回复:  60%|██████    | 18/30 [12:16<09:30, 47.50s/it]生成 Base Qwen1.5-4B 的回复:  63%|██████▎   | 19/30 [12:52<08:04, 44.07s/it]生成 Base Qwen1.5-4B 的回复:  67%|██████▋   | 20/30 [13:48<07:54, 47.47s/it]生成 Base Qwen1.5-4B 的回复:  70%|███████   | 21/30 [14:42<07:27, 49.70s/it]生成 Base Qwen1.5-4B 的回复:  73%|███████▎  | 22/30 [15:21<06:10, 46.36s/it]生成 Base Qwen1.5-4B 的回复:  77%|███████▋  | 23/30 [16:16<05:42, 48.86s/it]生成 Base Qwen1.5-4B 的回复:  80%|████████  | 24/30 [17:10<05:03, 50.53s/it]生成 Base Qwen1.5-4B 的回复:  83%|████████▎ | 25/30 [18:07<04:21, 52.39s/it]生成 Base Qwen1.5-4B 的回复:  87%|████████▋ | 26/30 [19:18<03:52, 58.02s/it]生成 Base Qwen1.5-4B 的回复:  90%|█████████ | 27/30 [20:05<02:44, 54.79s/it]生成 Base Qwen1.5-4B 的回复:  93%|█████████▎| 28/30 [21:14<01:57, 58.98s/it]生成 Base Qwen1.5-4B 的回复:  97%|█████████▋| 29/30 [22:18<01:00, 60.57s/it]生成 Base Qwen1.5-4B 的回复: 100%|██████████| 30/30 [23:29<00:00, 63.58s/it]生成 Base Qwen1.5-4B 的回复: 100%|██████████| 30/30 [23:29<00:00, 46.98s/it]
清理模型内存...
模型已从GPU中移除
Computing BLEU/ROUGE: 0it [00:00, ?it/s]Computing BLEU/ROUGE: 2it [00:00, 15.86it/s]Computing BLEU/ROUGE: 4it [00:00, 17.47it/s]Computing BLEU/ROUGE: 6it [00:00, 18.02it/s]Computing BLEU/ROUGE: 9it [00:00, 17.73it/s]Computing BLEU/ROUGE: 11it [00:00, 14.12it/s]Computing BLEU/ROUGE: 13it [00:00, 14.81it/s]Computing BLEU/ROUGE: 15it [00:01, 12.25it/s]Computing BLEU/ROUGE: 17it [00:01, 11.93it/s]Computing BLEU/ROUGE: 19it [00:01, 12.84it/s]Computing BLEU/ROUGE: 21it [00:01, 12.00it/s]Computing BLEU/ROUGE: 23it [00:01, 11.16it/s]Computing BLEU/ROUGE: 25it [00:01, 11.06it/s]Computing BLEU/ROUGE: 27it [00:02, 10.41it/s]Computing BLEU/ROUGE: 29it [00:02,  9.55it/s]Computing BLEU/ROUGE: 30it [00:02, 12.21it/s]
Computing Safety Scores:   0%|          | 0/30 [00:00<?, ?it/s]Computing Safety Scores:  13%|█▎        | 4/30 [00:00<00:00, 38.35it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Computing Safety Scores:  40%|████      | 12/30 [00:00<00:00, 60.29it/s]Computing Safety Scores:  67%|██████▋   | 20/30 [00:00<00:00, 68.90it/s]Computing Safety Scores:  93%|█████████▎| 28/30 [00:00<00:00, 73.11it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 68.84it/s]
评估完成: Base Qwen1.5-4B
  bleu: 0.0308
  rouge1: 0.3561
  rouge2: 0.0897
  rougeL: 0.1418
  tfidf_cosine: 0.3301
  safety: 0.5600
  empathy: 0.5020
  relevance: 0.9183
  avg_response_length: 4005.1333
  std_response_length: 1444.8638
  overall_score: 0.4255

评估模型: Finetuned Qwen1.5-4B
============================================================
加载模型: Qwen/Qwen1.5-4B (带适配器)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.52s/it]
  已加载适配器: ./model/finetuned-Qwen1.5-4B
  生成 Finetuned Qwen1.5-4B 的回复...
生成 Finetuned Qwen1.5-4B 的回复:   0%|          | 0/30 [00:00<?, ?it/s]生成 Finetuned Qwen1.5-4B 的回复:   3%|▎         | 1/30 [00:40<19:20, 40.01s/it]生成 Finetuned Qwen1.5-4B 的回复:   7%|▋         | 2/30 [01:19<18:34, 39.80s/it]生成 Finetuned Qwen1.5-4B 的回复:  10%|█         | 3/30 [03:50<40:43, 90.48s/it]生成 Finetuned Qwen1.5-4B 的回复:  13%|█▎        | 4/30 [04:55<34:47, 80.28s/it]生成 Finetuned Qwen1.5-4B 的回复:  17%|█▋        | 5/30 [06:04<31:49, 76.36s/it]生成 Finetuned Qwen1.5-4B 的回复:  20%|██        | 6/30 [07:03<28:09, 70.41s/it]生成 Finetuned Qwen1.5-4B 的回复:  23%|██▎       | 7/30 [07:45<23:24, 61.07s/it]生成 Finetuned Qwen1.5-4B 的回复:  27%|██▋       | 8/30 [08:59<23:58, 65.40s/it]生成 Finetuned Qwen1.5-4B 的回复:  30%|███       | 9/30 [09:39<20:04, 57.35s/it]生成 Finetuned Qwen1.5-4B 的回复:  33%|███▎      | 10/30 [10:31<18:34, 55.73s/it]生成 Finetuned Qwen1.5-4B 的回复:  37%|███▋      | 11/30 [11:26<17:35, 55.56s/it]生成 Finetuned Qwen1.5-4B 的回复:  40%|████      | 12/30 [11:56<14:19, 47.73s/it]生成 Finetuned Qwen1.5-4B 的回复:  43%|████▎     | 13/30 [13:03<15:11, 53.64s/it]生成 Finetuned Qwen1.5-4B 的回复:  47%|████▋     | 14/30 [14:29<16:51, 63.22s/it]生成 Finetuned Qwen1.5-4B 的回复:  50%|█████     | 15/30 [15:33<15:53, 63.55s/it]生成 Finetuned Qwen1.5-4B 的回复:  53%|█████▎    | 16/30 [16:48<15:38, 67.03s/it]生成 Finetuned Qwen1.5-4B 的回复:  57%|█████▋    | 17/30 [17:47<13:59, 64.57s/it]生成 Finetuned Qwen1.5-4B 的回复:  60%|██████    | 18/30 [18:21<11:05, 55.50s/it]生成 Finetuned Qwen1.5-4B 的回复:  63%|██████▎   | 19/30 [19:03<09:23, 51.24s/it]生成 Finetuned Qwen1.5-4B 的回复:  67%|██████▋   | 20/30 [19:57<08:41, 52.18s/it]生成 Finetuned Qwen1.5-4B 的回复:  70%|███████   | 21/30 [20:53<08:00, 53.36s/it]生成 Finetuned Qwen1.5-4B 的回复:  73%|███████▎  | 22/30 [21:39<06:49, 51.18s/it]生成 Finetuned Qwen1.5-4B 的回复:  77%|███████▋  | 23/30 [22:20<05:36, 48.06s/it]生成 Finetuned Qwen1.5-4B 的回复:  80%|████████  | 24/30 [22:50<04:16, 42.76s/it]生成 Finetuned Qwen1.5-4B 的回复:  83%|████████▎ | 25/30 [23:36<03:38, 43.75s/it]生成 Finetuned Qwen1.5-4B 的回复:  87%|████████▋ | 26/30 [24:17<02:51, 42.86s/it]生成 Finetuned Qwen1.5-4B 的回复:  90%|█████████ | 27/30 [25:13<02:20, 46.69s/it]生成 Finetuned Qwen1.5-4B 的回复:  93%|█████████▎| 28/30 [26:00<01:33, 46.75s/it]生成 Finetuned Qwen1.5-4B 的回复:  97%|█████████▋| 29/30 [26:50<00:47, 47.84s/it]生成 Finetuned Qwen1.5-4B 的回复: 100%|██████████| 30/30 [27:03<00:00, 37.30s/it]生成 Finetuned Qwen1.5-4B 的回复: 100%|██████████| 30/30 [27:03<00:00, 54.11s/it]
清理模型内存...
模型已从GPU中移除
Computing BLEU/ROUGE: 0it [00:00, ?it/s]Computing BLEU/ROUGE: 4it [00:00, 32.53it/s]Computing BLEU/ROUGE: 8it [00:00, 27.98it/s]Computing BLEU/ROUGE: 11it [00:00, 27.58it/s]Computing BLEU/ROUGE: 14it [00:00, 26.47it/s]Computing BLEU/ROUGE: 17it [00:00, 22.75it/s]Computing BLEU/ROUGE: 20it [00:00, 23.15it/s]Computing BLEU/ROUGE: 23it [00:00, 24.73it/s]Computing BLEU/ROUGE: 26it [00:01, 25.29it/s]Computing BLEU/ROUGE: 29it [00:01, 21.15it/s]Computing BLEU/ROUGE: 30it [00:01, 24.54it/s]
Computing Safety Scores:   0%|          | 0/30 [00:00<?, ?it/s]Computing Safety Scores:  33%|███▎      | 10/30 [00:00<00:00, 96.96it/s]Computing Safety Scores:  67%|██████▋   | 20/30 [00:00<00:00, 98.01it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 98.75it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 98.39it/s]
WARNING:transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm:Setting eos_token is not supported, use the default one.
WARNING:transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm:Setting pad_token is not supported, use the default one.
WARNING:transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm:Setting unk_token is not supported, use the default one.
评估完成: Finetuned Qwen1.5-4B
  bleu: 0.0769
  rouge1: 0.5155
  rouge2: 0.1649
  rougeL: 0.2302
  tfidf_cosine: 0.4936
  safety: 0.6333
  empathy: 0.7061
  relevance: 0.9114
  avg_response_length: 2125.9000
  std_response_length: 615.9727
  overall_score: 0.5247

评估模型: Base chatglm3-6b
============================================================
加载模型: THUDM/chatglm3-6b
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:03<00:21,  3.57s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:07<00:18,  3.69s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:11<00:14,  3.70s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:14<00:10,  3.63s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:18<00:07,  3.68s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:22<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:24<00:00,  3.16s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:24<00:00,  3.44s/it]
  生成 Base chatglm3-6b 的回复...
生成 Base chatglm3-6b 的回复:   0%|          | 0/30 [00:00<?, ?it/s]生成 Base chatglm3-6b 的回复:   3%|▎         | 1/30 [00:10<05:03, 10.48s/it]生成 Base chatglm3-6b 的回复:   7%|▋         | 2/30 [00:20<04:53, 10.46s/it]生成 Base chatglm3-6b 的回复:  10%|█         | 3/30 [00:31<04:44, 10.53s/it]生成 Base chatglm3-6b 的回复:  13%|█▎        | 4/30 [00:42<04:43, 10.89s/it]生成 Base chatglm3-6b 的回复:  17%|█▋        | 5/30 [01:04<06:08, 14.74s/it]生成 Base chatglm3-6b 的回复:  20%|██        | 6/30 [01:13<05:07, 12.80s/it]生成 Base chatglm3-6b 的回复:  23%|██▎       | 7/30 [01:22<04:23, 11.45s/it]生成 Base chatglm3-6b 的回复:  27%|██▋       | 8/30 [01:31<03:58, 10.84s/it]生成 Base chatglm3-6b 的回复:  30%|███       | 9/30 [01:37<03:17,  9.38s/it]生成 Base chatglm3-6b 的回复:  33%|███▎      | 10/30 [01:51<03:34, 10.75s/it]生成 Base chatglm3-6b 的回复:  37%|███▋      | 11/30 [02:05<03:40, 11.62s/it]生成 Base chatglm3-6b 的回复:  40%|████      | 12/30 [02:17<03:31, 11.77s/it]生成 Base chatglm3-6b 的回复:  43%|████▎     | 13/30 [02:30<03:25, 12.09s/it]生成 Base chatglm3-6b 的回复:  47%|████▋     | 14/30 [02:34<02:36,  9.80s/it]生成 Base chatglm3-6b 的回复:  50%|█████     | 15/30 [02:42<02:18,  9.21s/it]生成 Base chatglm3-6b 的回复:  53%|█████▎    | 16/30 [02:48<01:54,  8.18s/it]生成 Base chatglm3-6b 的回复:  57%|█████▋    | 17/30 [02:59<01:59,  9.17s/it]生成 Base chatglm3-6b 的回复:  60%|██████    | 18/30 [03:11<01:58,  9.87s/it]生成 Base chatglm3-6b 的回复:  63%|██████▎   | 19/30 [03:20<01:44,  9.50s/it]生成 Base chatglm3-6b 的回复:  67%|██████▋   | 20/30 [03:33<01:47, 10.72s/it]生成 Base chatglm3-6b 的回复:  70%|███████   | 21/30 [03:38<01:20,  8.92s/it]生成 Base chatglm3-6b 的回复:  73%|███████▎  | 22/30 [03:48<01:15,  9.41s/it]生成 Base chatglm3-6b 的回复:  77%|███████▋  | 23/30 [03:57<01:03,  9.08s/it]生成 Base chatglm3-6b 的回复:  80%|████████  | 24/30 [04:00<00:44,  7.42s/it]生成 Base chatglm3-6b 的回复:  83%|████████▎ | 25/30 [04:13<00:45,  9.00s/it]生成 Base chatglm3-6b 的回复:  87%|████████▋ | 26/30 [04:22<00:35,  8.97s/it]生成 Base chatglm3-6b 的回复:  90%|█████████ | 27/30 [04:35<00:30, 10.13s/it]生成 Base chatglm3-6b 的回复:  93%|█████████▎| 28/30 [04:57<00:27, 13.72s/it]生成 Base chatglm3-6b 的回复:  97%|█████████▋| 29/30 [05:07<00:12, 12.63s/it]生成 Base chatglm3-6b 的回复: 100%|██████████| 30/30 [05:15<00:00, 11.33s/it]生成 Base chatglm3-6b 的回复: 100%|██████████| 30/30 [05:15<00:00, 10.52s/it]
清理模型内存...
模型已从GPU中移除
Computing BLEU/ROUGE: 0it [00:00, ?it/s]Computing BLEU/ROUGE: 4it [00:00, 38.12it/s]Computing BLEU/ROUGE: 8it [00:00, 35.53it/s]Computing BLEU/ROUGE: 12it [00:00, 35.74it/s]Computing BLEU/ROUGE: 17it [00:00, 37.73it/s]Computing BLEU/ROUGE: 21it [00:00, 37.61it/s]Computing BLEU/ROUGE: 25it [00:00, 36.76it/s]Computing BLEU/ROUGE: 29it [00:00, 30.31it/s]Computing BLEU/ROUGE: 30it [00:00, 34.49it/s]
Computing Safety Scores:   0%|          | 0/30 [00:00<?, ?it/s]Computing Safety Scores:  33%|███▎      | 10/30 [00:00<00:00, 98.51it/s]Computing Safety Scores:  70%|███████   | 21/30 [00:00<00:00, 99.86it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 100.37it/s]
WARNING:transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm:Setting eos_token is not supported, use the default one.
WARNING:transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm:Setting pad_token is not supported, use the default one.
WARNING:transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm:Setting unk_token is not supported, use the default one.
评估完成: Base chatglm3-6b
  bleu: 0.0453
  rouge1: 0.4711
  rouge2: 0.1365
  rougeL: 0.2111
  tfidf_cosine: 0.4638
  safety: 0.6833
  empathy: 0.8661
  relevance: 0.8843
  avg_response_length: 1292.4333
  std_response_length: 524.6264
  overall_score: 0.5506

评估模型: Finetuned chatglm3-6b
============================================================
加载模型: THUDM/chatglm3-6b (带适配器)
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:03<00:21,  3.52s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:07<00:18,  3.67s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:11<00:14,  3.69s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:14<00:10,  3.61s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:18<00:07,  3.67s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:21<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:24<00:00,  3.15s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:24<00:00,  3.43s/it]
  已加载适配器: ./model/finetuned-chatglm3-6B
  生成 Finetuned chatglm3-6b 的回复...
生成 Finetuned chatglm3-6b 的回复:   0%|          | 0/30 [00:00<?, ?it/s]生成 Finetuned chatglm3-6b 的回复:   3%|▎         | 1/30 [00:05<02:40,  5.53s/it]生成 Finetuned chatglm3-6b 的回复:   7%|▋         | 2/30 [00:24<06:10, 13.25s/it]生成 Finetuned chatglm3-6b 的回复:  10%|█         | 3/30 [00:52<09:03, 20.13s/it]生成 Finetuned chatglm3-6b 的回复:  13%|█▎        | 4/30 [01:22<10:22, 23.96s/it]生成 Finetuned chatglm3-6b 的回复:  17%|█▋        | 5/30 [01:54<11:15, 27.02s/it]生成 Finetuned chatglm3-6b 的回复:  20%|██        | 6/30 [02:19<10:28, 26.18s/it]生成 Finetuned chatglm3-6b 的回复:  23%|██▎       | 7/30 [02:32<08:25, 21.96s/it]生成 Finetuned chatglm3-6b 的回复:  27%|██▋       | 8/30 [02:43<06:49, 18.60s/it]生成 Finetuned chatglm3-6b 的回复:  30%|███       | 9/30 [02:49<05:04, 14.51s/it]生成 Finetuned chatglm3-6b 的回复:  33%|███▎      | 10/30 [03:24<06:56, 20.83s/it]生成 Finetuned chatglm3-6b 的回复:  37%|███▋      | 11/30 [03:38<05:54, 18.67s/it]生成 Finetuned chatglm3-6b 的回复:  40%|████      | 12/30 [03:49<04:55, 16.40s/it]生成 Finetuned chatglm3-6b 的回复:  43%|████▎     | 13/30 [04:18<05:43, 20.18s/it]生成 Finetuned chatglm3-6b 的回复:  47%|████▋     | 14/30 [04:23<04:11, 15.71s/it]生成 Finetuned chatglm3-6b 的回复:  50%|█████     | 15/30 [04:59<05:24, 21.65s/it]生成 Finetuned chatglm3-6b 的回复:  53%|█████▎    | 16/30 [05:21<05:06, 21.90s/it]生成 Finetuned chatglm3-6b 的回复:  57%|█████▋    | 17/30 [05:50<05:12, 24.07s/it]生成 Finetuned chatglm3-6b 的回复:  60%|██████    | 18/30 [05:58<03:50, 19.21s/it]生成 Finetuned chatglm3-6b 的回复:  63%|██████▎   | 19/30 [06:24<03:54, 21.35s/it]生成 Finetuned chatglm3-6b 的回复:  67%|██████▋   | 20/30 [06:47<03:37, 21.78s/it]生成 Finetuned chatglm3-6b 的回复:  70%|███████   | 21/30 [06:54<02:36, 17.38s/it]生成 Finetuned chatglm3-6b 的回复:  73%|███████▎  | 22/30 [07:22<02:43, 20.48s/it]生成 Finetuned chatglm3-6b 的回复:  77%|███████▋  | 23/30 [07:50<02:39, 22.76s/it]生成 Finetuned chatglm3-6b 的回复:  80%|████████  | 24/30 [07:55<01:44, 17.46s/it]生成 Finetuned chatglm3-6b 的回复:  83%|████████▎ | 25/30 [08:30<01:52, 22.53s/it]生成 Finetuned chatglm3-6b 的回复:  87%|████████▋ | 26/30 [08:56<01:34, 23.65s/it]生成 Finetuned chatglm3-6b 的回复:  90%|█████████ | 27/30 [09:29<01:19, 26.45s/it]生成 Finetuned chatglm3-6b 的回复:  93%|█████████▎| 28/30 [09:55<00:52, 26.43s/it]生成 Finetuned chatglm3-6b 的回复:  97%|█████████▋| 29/30 [10:24<00:27, 27.15s/it]生成 Finetuned chatglm3-6b 的回复: 100%|██████████| 30/30 [10:31<00:00, 20.94s/it]生成 Finetuned chatglm3-6b 的回复: 100%|██████████| 30/30 [10:31<00:00, 21.03s/it]
清理模型内存...
模型已从GPU中移除
Computing BLEU/ROUGE: 0it [00:00, ?it/s]Computing BLEU/ROUGE: 4it [00:00, 27.59it/s]Computing BLEU/ROUGE: 7it [00:00, 25.20it/s]Computing BLEU/ROUGE: 11it [00:00, 30.40it/s]Computing BLEU/ROUGE: 15it [00:00, 29.56it/s]Computing BLEU/ROUGE: 19it [00:00, 28.61it/s]Computing BLEU/ROUGE: 23it [00:00, 27.98it/s]Computing BLEU/ROUGE: 26it [00:00, 27.39it/s]Computing BLEU/ROUGE: 29it [00:01, 22.65it/s]Computing BLEU/ROUGE: 30it [00:01, 26.61it/s]
Computing Safety Scores:   0%|          | 0/30 [00:00<?, ?it/s]Computing Safety Scores:  33%|███▎      | 10/30 [00:00<00:00, 92.49it/s]Computing Safety Scores:  67%|██████▋   | 20/30 [00:00<00:00, 95.70it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 95.95it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 95.47it/s]
评估完成: Finetuned chatglm3-6b
  bleu: 0.0920
  rouge1: 0.5291
  rouge2: 0.1865
  rougeL: 0.2478
  tfidf_cosine: 0.5008
  safety: 0.7500
  empathy: 0.7107
  relevance: 0.8558
  avg_response_length: 1744.4000
  std_response_length: 867.5476
  overall_score: 0.5466

评估模型: Base Qwen2.5-7B
============================================================
加载模型: Qwen/Qwen2.5-7B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.35s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.20s/it]
  生成 Base Qwen2.5-7B 的回复...
生成 Base Qwen2.5-7B 的回复:   0%|          | 0/30 [00:00<?, ?it/s]生成 Base Qwen2.5-7B 的回复:   3%|▎         | 1/30 [00:13<06:29, 13.43s/it]生成 Base Qwen2.5-7B 的回复:   7%|▋         | 2/30 [00:23<05:25, 11.62s/it]生成 Base Qwen2.5-7B 的回复:  10%|█         | 3/30 [00:32<04:35, 10.19s/it]生成 Base Qwen2.5-7B 的回复:  13%|█▎        | 4/30 [00:44<04:48, 11.10s/it]生成 Base Qwen2.5-7B 的回复:  17%|█▋        | 5/30 [01:02<05:33, 13.35s/it]生成 Base Qwen2.5-7B 的回复:  20%|██        | 6/30 [01:19<05:55, 14.81s/it]生成 Base Qwen2.5-7B 的回复:  23%|██▎       | 7/30 [01:29<05:02, 13.17s/it]生成 Base Qwen2.5-7B 的回复:  27%|██▋       | 8/30 [01:36<04:09, 11.32s/it]生成 Base Qwen2.5-7B 的回复:  30%|███       | 9/30 [01:51<04:21, 12.45s/it]生成 Base Qwen2.5-7B 的回复:  33%|███▎      | 10/30 [01:57<03:24, 10.24s/it]生成 Base Qwen2.5-7B 的回复:  37%|███▋      | 11/30 [02:04<02:55,  9.26s/it]生成 Base Qwen2.5-7B 的回复:  40%|████      | 12/30 [02:09<02:26,  8.12s/it]生成 Base Qwen2.5-7B 的回复:  43%|████▎     | 13/30 [02:22<02:42,  9.56s/it]生成 Base Qwen2.5-7B 的回复:  47%|████▋     | 14/30 [02:23<01:53,  7.09s/it]生成 Base Qwen2.5-7B 的回复:  50%|█████     | 15/30 [02:36<02:09,  8.66s/it]生成 Base Qwen2.5-7B 的回复:  53%|█████▎    | 16/30 [02:37<01:31,  6.57s/it]生成 Base Qwen2.5-7B 的回复:  57%|█████▋    | 17/30 [02:49<01:44,  8.07s/it]生成 Base Qwen2.5-7B 的回复:  60%|██████    | 18/30 [02:58<01:39,  8.32s/it]生成 Base Qwen2.5-7B 的回复:  63%|██████▎   | 19/30 [03:04<01:24,  7.66s/it]生成 Base Qwen2.5-7B 的回复:  67%|██████▋   | 20/30 [03:16<01:30,  9.09s/it]生成 Base Qwen2.5-7B 的回复:  70%|███████   | 21/30 [03:34<01:45, 11.77s/it]生成 Base Qwen2.5-7B 的回复:  73%|███████▎  | 22/30 [03:47<01:34, 11.86s/it]生成 Base Qwen2.5-7B 的回复:  77%|███████▋  | 23/30 [03:53<01:12, 10.37s/it]生成 Base Qwen2.5-7B 的回复:  80%|████████  | 24/30 [04:00<00:55,  9.30s/it]生成 Base Qwen2.5-7B 的回复:  83%|████████▎ | 25/30 [04:09<00:45,  9.13s/it]生成 Base Qwen2.5-7B 的回复:  87%|████████▋ | 26/30 [04:20<00:38,  9.58s/it]生成 Base Qwen2.5-7B 的回复:  90%|█████████ | 27/30 [04:35<00:34, 11.37s/it]生成 Base Qwen2.5-7B 的回复:  93%|█████████▎| 28/30 [04:46<00:22, 11.07s/it]生成 Base Qwen2.5-7B 的回复:  97%|█████████▋| 29/30 [05:03<00:13, 13.03s/it]生成 Base Qwen2.5-7B 的回复: 100%|██████████| 30/30 [05:13<00:00, 12.13s/it]生成 Base Qwen2.5-7B 的回复: 100%|██████████| 30/30 [05:13<00:00, 10.45s/it]
清理模型内存...
模型已从GPU中移除
Computing BLEU/ROUGE: 0it [00:00, ?it/s]Computing BLEU/ROUGE: 4it [00:00, 34.94it/s]Computing BLEU/ROUGE: 8it [00:00, 30.86it/s]Computing BLEU/ROUGE: 13it [00:00, 35.54it/s]Computing BLEU/ROUGE: 18it [00:00, 39.62it/s]Computing BLEU/ROUGE: 23it [00:00, 36.82it/s]Computing BLEU/ROUGE: 27it [00:00, 35.06it/s]Computing BLEU/ROUGE: 30it [00:00, 34.44it/s]
Computing Safety Scores:   0%|          | 0/30 [00:00<?, ?it/s]Computing Safety Scores:  33%|███▎      | 10/30 [00:00<00:00, 95.48it/s]Computing Safety Scores:  70%|███████   | 21/30 [00:00<00:00, 98.24it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 97.87it/s]
评估完成: Base Qwen2.5-7B
  bleu: 0.0245
  rouge1: 0.4009
  rouge2: 0.0869
  rougeL: 0.1710
  tfidf_cosine: 0.3604
  safety: 0.6133
  empathy: 0.8875
  relevance: 0.7483
  avg_response_length: 1412.4667
  std_response_length: 617.5013
  overall_score: 0.4958

评估模型: Finetuned Qwen2.5-7B
============================================================
加载模型: Qwen/Qwen2.5-7B (带适配器)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.08s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.04s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.09s/it]
  已加载适配器: ./model/finetuned-Qwen2.5-7B
  生成 Finetuned Qwen2.5-7B 的回复...
生成 Finetuned Qwen2.5-7B 的回复:   0%|          | 0/30 [00:00<?, ?it/s]生成 Finetuned Qwen2.5-7B 的回复:   3%|▎         | 1/30 [00:28<13:45, 28.48s/it]生成 Finetuned Qwen2.5-7B 的回复:   7%|▋         | 2/30 [00:56<13:07, 28.11s/it]生成 Finetuned Qwen2.5-7B 的回复:  10%|█         | 3/30 [01:28<13:24, 29.78s/it]生成 Finetuned Qwen2.5-7B 的回复:  13%|█▎        | 4/30 [01:56<12:42, 29.31s/it]生成 Finetuned Qwen2.5-7B 的回复:  17%|█▋        | 5/30 [02:34<13:28, 32.34s/it]生成 Finetuned Qwen2.5-7B 的回复:  20%|██        | 6/30 [03:05<12:49, 32.06s/it]生成 Finetuned Qwen2.5-7B 的回复:  23%|██▎       | 7/30 [03:32<11:33, 30.15s/it]生成 Finetuned Qwen2.5-7B 的回复:  27%|██▋       | 8/30 [03:51<09:44, 26.56s/it]生成 Finetuned Qwen2.5-7B 的回复:  30%|███       | 9/30 [04:10<08:31, 24.38s/it]生成 Finetuned Qwen2.5-7B 的回复:  33%|███▎      | 10/30 [04:38<08:30, 25.52s/it]生成 Finetuned Qwen2.5-7B 的回复:  37%|███▋      | 11/30 [05:09<08:36, 27.20s/it]生成 Finetuned Qwen2.5-7B 的回复:  40%|████      | 12/30 [05:29<07:28, 24.92s/it]生成 Finetuned Qwen2.5-7B 的回复:  43%|████▎     | 13/30 [05:59<07:29, 26.42s/it]生成 Finetuned Qwen2.5-7B 的回复:  47%|████▋     | 14/30 [06:23<06:51, 25.74s/it]生成 Finetuned Qwen2.5-7B 的回复:  50%|█████     | 15/30 [07:00<07:16, 29.09s/it]生成 Finetuned Qwen2.5-7B 的回复:  53%|█████▎    | 16/30 [07:34<07:09, 30.65s/it]生成 Finetuned Qwen2.5-7B 的回复:  57%|█████▋    | 17/30 [08:03<06:30, 30.00s/it]生成 Finetuned Qwen2.5-7B 的回复:  60%|██████    | 18/30 [08:51<07:08, 35.69s/it]生成 Finetuned Qwen2.5-7B 的回复:  63%|██████▎   | 19/30 [09:23<06:19, 34.52s/it]生成 Finetuned Qwen2.5-7B 的回复:  67%|██████▋   | 20/30 [10:12<06:28, 38.86s/it]生成 Finetuned Qwen2.5-7B 的回复:  70%|███████   | 21/30 [10:35<05:06, 34.05s/it]生成 Finetuned Qwen2.5-7B 的回复:  73%|███████▎  | 22/30 [10:56<04:01, 30.23s/it]生成 Finetuned Qwen2.5-7B 的回复:  77%|███████▋  | 23/30 [11:32<03:42, 31.72s/it]生成 Finetuned Qwen2.5-7B 的回复:  80%|████████  | 24/30 [11:49<02:45, 27.57s/it]生成 Finetuned Qwen2.5-7B 的回复:  83%|████████▎ | 25/30 [12:16<02:16, 27.35s/it]生成 Finetuned Qwen2.5-7B 的回复:  87%|████████▋ | 26/30 [12:46<01:52, 28.08s/it]生成 Finetuned Qwen2.5-7B 的回复:  90%|█████████ | 27/30 [13:29<01:37, 32.44s/it]生成 Finetuned Qwen2.5-7B 的回复:  93%|█████████▎| 28/30 [14:04<01:06, 33.25s/it]生成 Finetuned Qwen2.5-7B 的回复:  97%|█████████▋| 29/30 [14:42<00:34, 34.69s/it]生成 Finetuned Qwen2.5-7B 的回复: 100%|██████████| 30/30 [15:04<00:00, 30.97s/it]生成 Finetuned Qwen2.5-7B 的回复: 100%|██████████| 30/30 [15:04<00:00, 30.16s/it]
清理模型内存...
模型已从GPU中移除
Computing BLEU/ROUGE: 0it [00:00, ?it/s]Computing BLEU/ROUGE: 4it [00:00, 28.23it/s]Computing BLEU/ROUGE: 7it [00:00, 25.76it/s]Computing BLEU/ROUGE: 11it [00:00, 29.55it/s]Computing BLEU/ROUGE: 15it [00:00, 28.38it/s]Computing BLEU/ROUGE: 18it [00:00, 27.09it/s]Computing BLEU/ROUGE: 21it [00:00, 25.15it/s]Computing BLEU/ROUGE: 25it [00:00, 26.06it/s]Computing BLEU/ROUGE: 28it [00:01, 22.97it/s]Computing BLEU/ROUGE: 30it [00:01, 25.11it/s]
Computing Safety Scores:   0%|          | 0/30 [00:00<?, ?it/s]Computing Safety Scores:  33%|███▎      | 10/30 [00:00<00:00, 97.92it/s]Computing Safety Scores:  70%|███████   | 21/30 [00:00<00:00, 100.66it/s]Computing Safety Scores: 100%|██████████| 30/30 [00:00<00:00, 100.74it/s]
评估完成: Finetuned Qwen2.5-7B
  bleu: 0.0769
  rouge1: 0.5265
  rouge2: 0.1661
  rougeL: 0.2279
  tfidf_cosine: 0.4890
  safety: 0.7167
  empathy: 0.7609
  relevance: 0.9152
  avg_response_length: 2062.0333
  std_response_length: 565.3293
  overall_score: 0.5519

================================================================================
模型对比结果
================================================================================
                         bleu  rougeL  ...  relevance  overall_score
Base Qwen1.5-4B        0.0308  0.1418  ...     0.9183         0.4255
Finetuned Qwen1.5-4B   0.0769  0.2302  ...     0.9114         0.5247
Base chatglm3-6b       0.0453  0.2111  ...     0.8843         0.5506
Finetuned chatglm3-6b  0.0920  0.2478  ...     0.8558         0.5466
Base Qwen2.5-7B        0.0245  0.1710  ...     0.7483         0.4958
Finetuned Qwen2.5-7B   0.0769  0.2279  ...     0.9152         0.5519

[6 rows x 7 columns]
Traceback (most recent call last):
  File "scorer.py", line 671, in <module>
    results, df = main()
  File "scorer.py", line 624, in main
    comparison_df.to_csv(results_file)
  File "/usr/src/myenv/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/usr/src/myenv/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
    csv_formatter.save()
  File "/usr/src/myenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
    with get_handle(
  File "/usr/src/myenv/lib/python3.8/site-packages/pandas/io/common.py", line 737, in get_handle
    check_parent_directory(str(handle))
  File "/usr/src/myenv/lib/python3.8/site-packages/pandas/io/common.py", line 600, in check_parent_directory
    raise OSError(rf"Cannot save file into a non-existent directory: '{parent}'")
OSError: Cannot save file into a non-existent directory: 'figures/scorer'
